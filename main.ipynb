{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.append('/content/drive/MyDrive/Pose_Detection')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"spjHPxRxQh4a","executionInfo":{"status":"ok","timestamp":1655146572758,"user_tz":-480,"elapsed":2429,"user":{"displayName":"林佑檍","userId":"10256136389189092655"}},"outputId":"fa3f6889-439f-4ec7-eaa4-0acab86566dc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"CKZ4IZ-qQf6e","executionInfo":{"status":"ok","timestamp":1655146583920,"user_tz":-480,"elapsed":9871,"user":{"displayName":"林佑檍","userId":"10256136389189092655"}}},"outputs":[],"source":["import cv2\n","import numpy as np\n","from loaddata import loaddata\n","from sklearn import svm\n","from sklearn.metrics import classification_report\n","import tensorflow as tf\n","from tensorflow.data import Dataset\n","from tensorflow.keras import losses, Sequential, layers"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"AHEaDsC6Qf6h","executionInfo":{"status":"ok","timestamp":1655145505437,"user_tz":-480,"elapsed":20341,"user":{"displayName":"林佑檍","userId":"10256136389189092655"}}},"outputs":[],"source":["x_train, x_test, y_train, y_test = loaddata('1', '2', '3', train_size=0.8)"]},{"cell_type":"markdown","metadata":{"id":"I1_qHb_NQf6h"},"source":["---\n","### HOG"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ChQQtmH_Qf6i","executionInfo":{"status":"ok","timestamp":1655144109456,"user_tz":-480,"elapsed":10398,"user":{"displayName":"林佑檍","userId":"10256136389189092655"}}},"outputs":[],"source":["winSize = (160, 160) \n","blockSize = (80, 80)\n","blockStride = (40, 40)\n","cellSize = (80, 80)\n","Bin = 9 \n","hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, Bin)\n","HOG = lambda img: hog.compute(img).flatten()\n","\n","train_HOG = np.array([HOG(img) for img in x_train])\n","\n","SVM = svm.SVC(kernel = 'linear')\n","SVM.fit(train_HOG, y_train)\n","del train_HOG"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"jljjJ2JiQf6j","outputId":"eab7fc75-b47b-4755-b6ed-ecfa57ee0519","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655144114166,"user_tz":-480,"elapsed":2657,"user":{"displayName":"林佑檍","userId":"10256136389189092655"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.67      0.70      0.68       140\n","           1       0.56      0.66      0.60        59\n","           2       0.32      0.22      0.26        37\n","           3       0.33      0.26      0.30        34\n","           4       0.31      0.32      0.31        41\n","\n","    accuracy                           0.54       311\n","   macro avg       0.44      0.43      0.43       311\n","weighted avg       0.52      0.54      0.53       311\n","\n"]}],"source":["test_HOG = np.array([HOG(img) for img in x_test])\n","y_predict = SVM.predict(test_HOG)\n","print(classification_report(y_test, y_predict))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"T3pTZjCAQf6k","executionInfo":{"status":"ok","timestamp":1655144117338,"user_tz":-480,"elapsed":345,"user":{"displayName":"林佑檍","userId":"10256136389189092655"}}},"outputs":[],"source":["method_SVM = lambda img: SVM.predict([HOG(img)])[0]"]},{"cell_type":"markdown","metadata":{"id":"8blw3j4RQf6k"},"source":["---\n","### CNN"]},{"cell_type":"code","source":["import os\n","from sklearn.model_selection import train_test_split\n","def loaddata(folder1_path, folder2_path, folader3_path, train_size):\n","    folders = [folder1_path, folder2_path, folader3_path]\n","    X, Y = [], []\n","    for folder in folders:\n","        # get X from img\n","        data = os.path.join(folder, 'data')\n","        for root, dirs, files in os.walk(data):\n","            for name in files:               \n","                imgname = os.path.join(root, name)\n","                img = cv2.imread(str(imgname))\n","                img = cv2.resize(img, (160, 120), interpolation=cv2.INTER_AREA)\n","                X.append(img)\n","        label = os.path.join(folder, 'label.txt')\n","        # get Y from label.txt\n","        with open(label, 'r') as f:\n","            context = [int(i) for i in f.read().split()]\n","            Y += context\n","\n","    # split to train, valid\n","    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1-train_size, random_state=777)\n","    return x_train, x_test, y_train, y_test"],"metadata":{"id":"8BTL8cgBU9EI","executionInfo":{"status":"ok","timestamp":1655146585301,"user_tz":-480,"elapsed":2,"user":{"displayName":"林佑檍","userId":"10256136389189092655"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = loaddata('/content/drive/MyDrive/Pose_Detection/1', '/content/drive/MyDrive/Pose_Detection/2', '/content/drive/MyDrive/Pose_Detection/3', train_size=0.8)\n","print(np.array(x_train).shape)\n","print(np.array(x_test).shape)\n","print(np.array(y_train).shape)\n","print(np.array(y_test).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NSQTF99ZVfbw","executionInfo":{"status":"ok","timestamp":1655146611191,"user_tz":-480,"elapsed":23357,"user":{"displayName":"林佑檍","userId":"10256136389189092655"}},"outputId":"9b3d13a9-30c0-4895-d639-31c61222f9f1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(1243, 120, 160, 3)\n","(311, 120, 160, 3)\n","(1243,)\n","(311,)\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"j84LTYVhQf6k","executionInfo":{"status":"ok","timestamp":1655146612854,"user_tz":-480,"elapsed":2,"user":{"displayName":"林佑檍","userId":"10256136389189092655"}}},"outputs":[],"source":["def convModel():\n","    model = Sequential([\n","        layers.Conv2D(64, (3, 3), activation = 'relu'),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(32, (3, 3), activation = 'relu'),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(32, (3, 3), activation = 'relu'),\n","        layers.Flatten(),\n","        layers.Dense(10000, activation = 'relu'),\n","        layers.Dropout(0.2),\n","        layers.Dense(5, activation = 'softmax', name = \"final\")\n","    ])\n","    model.compile(optimizer = 'adam', loss = losses.SparseCategoricalCrossentropy(), metrics = ['accuracy'])\n","    return model\n","\n","CNN = convModel()"]},{"cell_type":"code","source":["CNN.fit(np.array(x_train).astype(float), np.array(y_train), batch_size=1, epochs=10)\n","CNN.evaluate(np.array(x_test).astype(float), np.array(y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y055J0BATFFn","executionInfo":{"status":"ok","timestamp":1655147494693,"user_tz":-480,"elapsed":794389,"user":{"displayName":"林佑檍","userId":"10256136389189092655"}},"outputId":"25bc7a09-0e47-40a1-8f4a-c3c30bb48e30"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["1243/1243 [==============================] - 786s 632ms/step - loss: 1.5051 - accuracy: 0.4489\n","10/10 [==============================] - 8s 759ms/step - loss: 1.4060 - accuracy: 0.4566\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.4059847593307495, 0.4565916359424591]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["y_predict = [np.argmax(CNN.predict(np.array([cv2.resize(img, (160, 120), interpolation=cv2.INTER_AREA)]).astype(float))) for img in x_test]\n","print(classification_report(y_test, y_predict))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tLSLc7LNlB36","executionInfo":{"status":"ok","timestamp":1655149721685,"user_tz":-480,"elapsed":32094,"user":{"displayName":"林佑檍","userId":"10256136389189092655"}},"outputId":"79866b44-8922-4d88-a351-f3fdc65d0b34"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.46      1.00      0.63       140\n","           1       0.00      0.00      0.00        59\n","           2       0.00      0.00      0.00        37\n","           3       0.00      0.00      0.00        34\n","           4       1.00      0.05      0.09        41\n","\n","    accuracy                           0.46       311\n","   macro avg       0.29      0.21      0.14       311\n","weighted avg       0.34      0.46      0.29       311\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["method_CNN = lambda img: np.argmax(CNN.predict(np.array([cv2.resize(img, (160, 120), interpolation=cv2.INTER_AREA)]).astype(float)))"],"metadata":{"id":"mg6GCc6tX76C","executionInfo":{"status":"ok","timestamp":1655149033174,"user_tz":-480,"elapsed":418,"user":{"displayName":"林佑檍","userId":"10256136389189092655"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EFE0NptmQf6l"},"source":["---\n","### online predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6P0NxJ90Qf6m"},"outputs":[],"source":["def onlinePredict(method):\n","    # empty: 0, up: 1, down: 2, left: 3, right: 4\n","    action = {0: 'empty', 1: 'up', 2: 'down', 3: 'right', 4: 'left'}\n","    cap = cv2.VideoCapture(0)\n","    if not cap.isOpened():\n","        print(\"Cannot open camera\")\n","        exit()\n","        \n","    while(True):\n","        # 擷取影像\n","        ret, frame = cap.read()\n","        if not ret:\n","            print(\"Can't receive frame (stream end?). Exiting ...\")\n","            break\n","        \n","        img = frame[:, ::-1]\n","        # 顯示圖片並預測\n","        cv2.imshow('live', img)\n","        predict = action[method(frame)]\n","        print(predict)\n","        \n","        # 按下 q 鍵離開迴圈\n","        if cv2.waitKey(1) == ord('q'):\n","            break\n","    cap.release()\n","    cv2.destroyAllWindows()\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7OEuLXpRQf6m"},"outputs":[],"source":["onlinePredict(method_SVM)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.8 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"3b6c1224657c578b9d3e2b49ca831d7f85bea0417468944a724420177cb04cf0"}},"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}